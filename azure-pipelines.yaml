name: Azure Pipelines

trigger:
  - main

variables:
  python_version: '3.7.6'
  azureServiceConnectionId: 'AzureDevopsConnection'
  projectRoot: $(System.DefaultWorkingDirectory)
  environmentName: 'test'
  storage_account_name: 'tfstate224873291'
  container_name: 'tfstate'
  key: 'test.terraform.tfstate'
  resource_group_name_storage: 'AzuredevopsRG'
  address_space: '["10.5.0.0/16"]'
  address_prefix_test: '["10.5.1.0/24"]'
  chrome_version: '114.0.5735.90'  # SpÃ©cifiez la version exacte de Chrome

stages:
  - stage: Build
    jobs:
      - job: BuildInfrastructure
        steps:
          # Install Terraform
          - task: ms-devlabs.custom-terraform-tasks.custom-terraform-installer-task.TerraformInstaller@0
            displayName: 'Install Terraform'
            inputs:
              terraformVersion: '1.2.9'

          # Initialize Terraform with Azure backend
          - task: ms-devlabs.custom-terraform-tasks.custom-terraform-release-task.TerraformTaskV3@3
            displayName: 'Terraform Init'
            inputs:
              provider: 'azurerm'
              command: 'init'
              commandOptions: '-input=false -lock=false -no-color -upgrade'
              workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/environments/test'
              backendServiceArm: '$(azureServiceConnectionId)'
              backendAzureRmResourceGroupName: '$(resource_group_name_storage)'
              backendAzureRmStorageAccountName: '$(storage_account_name)'
              backendAzureRmContainerName: '$(container_name)'
              backendAzureRmKey: '$(key)'
              backendAzureRmUseMsi: true

          # Validate Terraform configuration
          - task: ms-devlabs.custom-terraform-tasks.custom-terraform-release-task.TerraformTaskV3@3
            displayName: 'Terraform Validate'
            inputs:
              provider: 'azurerm'
              command: 'validate'

          # Apply Terraform configuration
          - task: ms-devlabs.custom-terraform-tasks.custom-terraform-release-task.TerraformTaskV3@3
            displayName: 'Terraform Apply'
            inputs:
              provider: 'azurerm'
              command: 'apply'
              workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/environments/test'
              environmentServiceNameAzureRM: '$(azureServiceConnectionId)'
              commandOptions: '-auto-approve'

          # Install Newman for API testing
          - task: CmdLine@2
            displayName: 'Install Newman'
            inputs:
              script: 'sudo npm install -g newman'
              workingDirectory: $(System.DefaultWorkingDirectory)

          # Run Data Validation Tests using Newman
          - task: CmdLine@2
            displayName: 'Run Data Validation Tests'
            continueOnError: true
            inputs:
              script: 'newman run DataValidationTestStarterAPIspostman_collection.json -e Test.environment.json --reporters cli,junit --reporter-junit-export TEST-DataValidation.xml'
              workingDirectory: '$(System.DefaultWorkingDirectory)/automatedtesting/postman'

          # Run Regression Tests using Newman
          - task: CmdLine@2
            displayName: 'Run Regression Tests'
            continueOnError: true
            inputs:
              script: 'newman run RegressionTestStarterAPIspostman_collection.json -e Test.environment.json --reporters cli,junit --reporter-junit-export TEST-Regression.xml'
              workingDirectory: '$(System.DefaultWorkingDirectory)/automatedtesting/postman'

          # Publish test results from Newman
          - task: PublishTestResults@2
            inputs:
              testResultsFormat: 'JUnit'
              testResultsFiles: '**/TEST-*.xml'
              searchFolder: '$(System.DefaultWorkingDirectory)/automatedtesting/postman'
              mergeTestResults: true
              testRunTitle: 'Postman Tests'

          # Archive UI test results
          - task: ArchiveFiles@2
            displayName: 'Archive UI Tests'
            inputs:
              rootFolderOrFile: '$(System.DefaultWorkingDirectory)/automatedtesting/selenium'
              includeRootFolder: false
              archiveType: 'zip'
              archiveFile: '$(Build.ArtifactStagingDirectory)/$(Build.BuildId)-uitests.zip'

          # Upload archived UI test results
          - publish: $(Build.ArtifactStagingDirectory)/$(Build.BuildId)-uitests.zip
            displayName: 'Upload UI Tests'
            artifact: drop-uitests

          # Archive FakeRestAPI test results
          - task: ArchiveFiles@2
            displayName: 'Archive FakeRestAPI'
            inputs:
              rootFolderOrFile: '$(System.DefaultWorkingDirectory)/automatedtesting/jmeter/fakerestapi'
              includeRootFolder: false
              archiveType: 'zip'
              archiveFile: '$(Build.ArtifactStagingDirectory)/$(Build.BuildId)-fakerestapi.zip'

          # Upload archived FakeRestAPI test results
          - publish: $(Build.ArtifactStagingDirectory)/$(Build.BuildId)-fakerestapi.zip
            displayName: 'Upload FakeRestAPI'
            artifact: drop-fakerestapi

          # Archive Performance Test Suite results
          - task: ArchiveFiles@2
            displayName: 'Archive Performance Test Suite'
            inputs:
              rootFolderOrFile: '$(System.DefaultWorkingDirectory)/automatedtesting/jmeter'
              includeRootFolder: false
              archiveType: 'zip'
              archiveFile: '$(Build.ArtifactStagingDirectory)/$(Build.BuildId)-perftests.zip'

          # Upload archived Performance Test Suite results
          - publish: $(Build.ArtifactStagingDirectory)/$(Build.BuildId)-perftests.zip
            displayName: 'Upload Performance Test Suite'
            artifact: drop-perftests

  - stage: Deploy
    dependsOn: Build
    jobs:
      - deployment: FakeRestAPI
        pool:
          vmImage: 'ubuntu-latest'
        environment: 'test'
        strategy:
          runOnce:
            deploy:
              steps:
                # Deploy FakeRestAPI to Azure Web App
                - task: AzureWebApp@1
                  displayName: 'Deploy Azure Web App'
                  inputs:
                    azureSubscription: '$(azureServiceConnectionId)'
                    appName: 'myapplication-ourobadiou-appservice'
                    appType: webApp
                    package: '$(Pipeline.Workspace)/drop-fakerestapi/$(Build.BuildId)-fakerestapi.zip'
                    deploymentMethod: 'auto'

                # Extract Performance Test Suite ZIP
                - task: Bash@3
                  displayName: 'Extract Performance Test Suite ZIP'
                  inputs:
                    targetType: 'inline'
                    script: |
                      mkdir -p /home/vsts/work/1/drop-perftests
                      unzip /home/vsts/work/1/drop-perftests/*perftests.zip -d /home/vsts/work/1/drop-perftests
                      ls -la /home/vsts/work/1/drop-perftests

                # Install JMeter for performance testing
                - task: Bash@3
                  displayName: 'Install JMeter'
                  inputs:
                    targetType: 'inline'
                    script: |
                      wget https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-5.6.2.tgz
                      tar -xzf apache-jmeter-5.6.2.tgz -C /home/vsts/work/1/drop-perftests
                      ls -la /home/vsts/work/1/drop-perftests/apache-jmeter-5.6.2

                # Run JMeter Stress Test
                - task: Bash@3
                  displayName: 'Run JMeter Stress Test'
                  inputs:
                    targetType: 'inline'
                    script: |
                      /home/vsts/work/1/drop-perftests/apache-jmeter-5.6.2/bin/jmeter -n -t /home/vsts/work/1/drop-perftests/StressTest.jmx \
                        -l /home/vsts/work/1/drop-perftests/log/jmeter/results_StressTest.csv \
                        -e -f -o /home/vsts/work/1/drop-perftests/log/jmeter/StressTestReport \
                        -j /home/vsts/work/1/drop-perftests/log/jmeter/JmeterStressTestReport.log \
                        -JexampleCSV=/home/vsts/work/1/drop-perftests/exempleCsv.csv \
                        -JresultsCSV=/home/vsts/work/1/drop-perftests/results.csv
                    workingDirectory: /home/vsts/work/1/drop-perftests

                # Run JMeter Endurance Test
                - task: Bash@3
                  displayName: 'Run JMeter Endurance Test'
                  inputs:
                    targetType: 'inline'
                    script: |
                      /home/vsts/work/1/drop-perftests/apache-jmeter-5.6.2/bin/jmeter -n -t /home/vsts/work/1/drop-perftests/EnduranceTest.jmx \
                        -l /home/vsts/work/1/drop-perftests/log/jmeter/results_EnduranceTest.csv \
                        -e -f -o /home/vsts/work/1/drop-perftests/log/jmeter/EnduranceTestReport \
                        -j /home/vsts/work/1/drop-perftests/log/jmeter/JmeterEnduranceTestReport.log \
                        -JexampleCSV=/home/vsts/work/1/drop-perftests/exempleCsv.csv \
                        -JresultsCSV=/home/vsts/work/1/drop-perftests/results.csv
                    workingDirectory: /home/vsts/work/1/drop-perftests

                # Extract Selenium UI Tests ZIP
                - task: Bash@3
                  displayName: 'Extract Selenium UI Tests ZIP'
                  inputs:
                    targetType: 'inline'
                    script: |
                      mkdir -p /home/vsts/work/1/drop-uitests
                      unzip /home/vsts/work/1/drop-uitests/*uitests.zip -d /home/vsts/work/1/drop-uitests
                      ls -la /home/vsts/work/1/drop-uitests

                # Install Selenium and ChromeDriver
                - task: Bash@3
                  displayName: 'Install Selenium and ChromeDriver'
                  inputs:
                    targetType: 'inline'
                    script: |
                      sudo apt-get update
                      sudo apt-get install python3-pip -y
                      sudo apt-get install unzip -y
                      sudo apt-get install -y chromium-browser
                      sudo apt-get install wget -y
                      pip3 install selenium
                      wget -O bin/chromedriver.zip $WEBDRIVER_PATH
                      rm -f bin/chromedriver
                      unzip -o -d bin bin/chromedriver.zip
                      rm bin/chromedriver.zip
                      echo "installation done"
                                            
                                            sudo mv chromedriver /usr/local/bin/
                                            sudo chmod +x /usr/local/bin/chromedriver

                      # Verify installation
                      chromedriver --version

                # Run Selenium Tests
                - task: Bash@3
                  displayName: 'Run Selenium Tests'
                  inputs:
                    targetType: 'inline'
                    script: |
                      # Ensure Chromedriver is correctly installed
                      chromedriver --version

                      # Run tests and log output
                      cd /home/vsts/work/1/drop-uitests
                      python3 add_remove_from_cart.py > selenium.log 2>&1
                      python3 login.py >> selenium.log 2>&1

                      # Ensure that the test process exits
                      echo "Tests completed. Check selenium.log for details."

                # Display the content of selenium.log
                - task: Bash@3
                  displayName: 'Display Selenium Log'
                  inputs:
                    targetType: 'inline'
                    script: |
                      echo "Displaying Selenium log content:"
                      cat /home/vsts/work/1/drop-uitests/selenium.log

                # Publish Selenium test results
                - task: PublishPipelineArtifact@1
                  displayName: 'Publish Selenium Logs'
                  inputs:
                    targetPath: '/home/vsts/work/1/drop-uitests/selenium.log'
                    artifactName: 'selenium-logs'
